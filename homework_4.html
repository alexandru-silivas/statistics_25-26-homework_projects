<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Homework 4 – Frequency Convergence & Law of Large Numbers</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <!-- NAVBAR -->
  <header class="navbar">
    <nav>
      <ul class="nav-links">
        <li><a href="index.html">Home</a></li>
        <li><a href="homework_1.html">HMWK 1</a></li>
        <li><a href="homework_2.html">HMWK 2</a></li>
        <li><a href="homework_3.html">HMWK 3</a></li>
        <li><a href="homework_4.html" class="active">HMWK 4</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <div class="main-content">
      <h1>Homework 4</h1>
      <hr class="section-separator" />

      <!-- ───────────────────────────── -->
      <!-- ASSIGNMENT 1 -->
      <!-- ───────────────────────────── -->
      <section id="assignment1">
        <h2>Assignment 1 — Understanding “Converge” in  
          <em>“The Frequency Converges to the Probability”</em>
        </h2>

        <p>
          In probability theory, the word <strong>“converge”</strong> refers to the process
          by which repeated experimental results become increasingly close to their expected
          theoretical value. Specifically, in the phrase
          <em>“the frequency converges to the probability”</em>, it means that as the number
          of trials increases, the <strong>observed frequency</strong> (the fraction of times
          an event occurs) approaches the <strong>true probability</strong> of that event.
        </p>

        <h3>1. Conceptual Overview</h3>
        <p>
          Consider tossing a fair coin. The theoretical probability of getting heads is 0.5.
          If you toss the coin only a few times, the observed frequency may differ from this
          value—perhaps 3 heads in 5 tosses (0.6). But as the number of tosses increases, the
          frequency will stabilize around 0.5.
        </p>

        <p>
          This behavior illustrates the <strong>Law of Large Numbers</strong>:
          as the number of trials grows, the sample frequency stabilizes and
          <em>converges</em> to the true probability.
        </p>

        <pre><code>P(A) = lim<sub>n→∞</sub> (Number of times A occurs) / n</code></pre>

        <h3>2. Visual Simulation — Coin Tosses</h3>
        <p>
          The following simulation shows this convergence effect.  
          Each coin toss has a 50% chance of being heads. As we increase the number
          of tosses, the <strong>observed frequency</strong> (blue line) approaches
          the <strong>theoretical probability</strong> (red dashed line).
        </p>

        <div id="coinChartContainer">
          <canvas id="coinChart"></canvas>
        </div>

        <div class="rsa-buttons">
          <button type="button" onclick="simulateCoinTosses()">Simulate 100 Tosses</button>
          <button type="button" onclick="resetCoinChart()">Reset</button>
        </div>

        <p id="coinStatus" class="status">Status: Waiting for simulation.</p>

        <h3>3. Why It Matters</h3>
        <p>
          Convergence explains why randomness can lead to predictability in the long run.
          It is the foundation of <strong>statistical inference</strong>, where we estimate
          probabilities from observed data, and of <strong>machine learning</strong>, where
          models learn stable patterns from repeated exposure to data.
        </p>

        <p>
          Thus, when we say that “frequency converges to probability,” we mean that randomness
          becomes predictable when averaged over many independent trials.
        </p>
      </section>

      <!-- VISUAL DIVIDER BETWEEN ASSIGNMENTS -->
      <hr class="section-separator" style="margin: 50px 0;" />

      <!-- ───────────────────────────── -->
      <!-- ASSIGNMENT 2 -->
      <!-- ───────────────────────────── -->
      <section id="assignment2">
        <h2>Assignment 2 — Representation of the Law of Large Numbers</h2>

        <p>
          The <strong>Law of Large Numbers (LLN)</strong> states that as the number of
          independent trials of a random experiment increases, the average of the results
          approaches the expected value. It formalizes the intuition behind convergence:
          large samples reduce randomness, leading to stable averages.
        </p>

        <p>
          We can represent this principle visually by showing how the running average of random
          results (like die rolls or coin tosses) gradually approaches the true expected value.
        </p>

        <div id="llnChartContainer">
          <canvas id="llnChart"></canvas>
        </div>

        <div class="rsa-buttons">
          <button type="button" onclick="simulateLLN()">Simulate 500 Trials</button>
          <button type="button" onclick="resetLLN()">Reset</button>
        </div>

        <p id="llnStatus" class="status">Status: Waiting for simulation.</p>

        <p>
          As the number of trials increases, the graph demonstrates that random variations
          tend to cancel out, and the average result converges toward the true mean —
          a core idea in both probability and data science.
        </p>
      </section>

      <hr />
      <a href="index.html" class="back-button">← Back to Home</a>
    </div>
  </main>

  <footer class="site-footer">
    © 2025 Alexandru Silivas — ID 2252622 —
    <a href="mailto:silivas.2252622@studenti.uniroma1.it">silivas.2252622@studenti.uniroma1.it</a>
  </footer>

  <!-- Chart.js -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  
  <!-- Homework 4 Simulations -->
  <script src="convergence_and_lln.js"></script>
  
</body>
</html>
