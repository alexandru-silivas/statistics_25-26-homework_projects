<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Homework 9 — Interpretations of Probability & Axioms</title>
  <link rel="stylesheet" href="style.css">

  <!-- MathJax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>

<body>

<header class="navbar">
  <nav>
    <ul class="nav-links">
      <li><a href="index.html">Home</a></li>
      <li><a href="homework_1.html">HMWK 1</a></li>
      <li><a href="homework_2.html">HMWK 2</a></li>
      <li><a href="homework_3.html">HMWK 3</a></li>
      <li><a href="homework_4.html">HMWK 4</a></li>
      <li><a href="homework_5.html">HMWK 5</a></li>
      <li><a href="homework_6.html">HMWK 6</a></li>
      <li><a href="homework_7.html">HMWK 7</a></li>
      <li><a href="homework_8.html">HMWK 8</a></li>
      <li><a href="homework_9.html" class="active">HMWK 9</a></li>
      <li><a href="homework_10.html">HMWK 10</a></li>
    </ul>
  </nav>
</header>

<main>
<div class="main-content">

  <h1>Homework 9</h1>
  <hr>
  <h2>Interpretations of Probability, Axioms, and Inclusion–Exclusion</h2>

  <p>
    This assignment explores the major interpretations of probability, the role of Kolmogorov’s axioms,
    and the deep connection between probability theory and measure theory. We conclude by deriving two
    fundamental consequences of the axioms: <em>subadditivity</em> and the
    <em>inclusion–exclusion principle</em>. These concepts unify the theoretical framework used in
    previous homeworks (especially Homeworks 4 and 7).
  </p>

  <!-- SECTION 1 ------------------------------------------------------------ -->
  <h3>1. Main Interpretations of Probability</h3>

  <p>Across history, several interpretations of probability have been proposed:</p>

  <ul>
    <li>
      <strong>Classical (Laplace) Interpretation</strong>:  
      Probability is the ratio of favorable to equally likely outcomes.  
      <br>Example:  
      $$P(\text{Heads}) = \frac{1}{2}$$
    </li>

    <li>
      <strong>Frequentist Interpretation</strong>:  
      Probability is the long-run relative frequency of an event.  
      <br>The Law of Large Numbers motivates this definition.
    </li>

    <li>
      <strong>Bayesian Interpretation</strong>:  
      Probability measures a degree of belief. It is updated through Bayes’ Theorem.  
      <br>Useful in security, threat modeling, and adaptive detection algorithms.
    </li>

    <li>
      <strong>Geometric Interpretation</strong>:  
      Probabilities are ratios of lengths, areas, or volumes.  
      <br>Example: picking a point uniformly in a region.
    </li>
  </ul>

  <p>
    These interpretations sometimes create conceptual tension (e.g., “probability of a unique event”).
    The modern resolution lies in the <strong>axiomatic approach</strong>.
  </p>


  <!-- SECTION 2 ------------------------------------------------------------ -->
  <h3>2. Kolmogorov's Axiomatic Approach</h3>

  <p>Kolmogorov formalized probability with three axioms:</p>

  <ol>
    <li><strong>Non-negativity</strong>:  
      $$P(A) \ge 0$$</li>

    <li><strong>Normalization</strong>:  
      $$P(\Omega) = 1$$</li>

    <li><strong>Countable additivity</strong> (disjoint events):  
      $$P\left(\bigcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty P(A_i)$$
    </li>
  </ol>

  <p>
    This framework is compatible with <em>all</em> interpretations of probability, removing contradictions
    between them by grounding probability in pure mathematics.
  </p>


  <!-- SECTION 3 ------------------------------------------------------------ -->
  <h3>3. Probability Theory & Measure Theory</h3>

  <p>
    Modern probability is built on <strong>measure theory</strong>. The mathematical structure is:
  </p>

  <ul>
    <li><strong>Sample space</strong> \( \Omega \)</li>
    <li><strong>σ-algebra</strong> \( \mathcal{F} \subseteq 2^\Omega \): collection of measurable events</li>
    <li><strong>Probability measure</strong> \( P: \mathcal{F} \to [0,1] \)</li>
  </ul>

  <p>Properties:</p>
  <ul>
    <li>Closed under countable unions</li>
    <li>Closed under complements</li>
    <li>Contains \(\Omega\)</li>
  </ul>

  <p>
    A <strong>random variable</strong> is simply a measurable function:
    $$X : \Omega \to \mathbb{R}.$$
    This transforms randomness into real numbers, enabling computation of expectations, variances,
    and convergence — concepts heavily used in previous homeworks (LLN in HW4 and random walks in HW7).
  </p>


  <!-- SECTION 4 ------------------------------------------------------------ -->
  <h3>4. Subadditivity & Inclusion–Exclusion</h3>

  <p>
    Two of the most important consequences of the probability axioms are the
    <strong>subadditivity inequality</strong> and the
    <strong>inclusion–exclusion principle</strong>.
  </p>

  <!-- SUBSECTION: SUBADDITIVITY -->
  <h4>4.1 Subadditivity</h4>

  <p>
    For <em>any</em> events \(A\) and \(B\), we have:
  </p>

  <p>
    $$P(A \cup B) \le P(A) + P(B)$$
  </p>

  <p><strong>Why this holds:</strong></p>
  <ul>
    <li>If \(A\) and \(B\) overlap, their intersection is counted twice in \(P(A)+P(B)\).</li>
    <li>Thus the sum always overestimates, while the union counts all outcomes once.</li>
  </ul>

  <p><strong>Example:</strong></p>
  <p>
    Let event \(A\) = “server delayed”, probability \(0.3\).  
    Let event \(B\) = “network outage”, probability \(0.2\).  
    They overlap with probability \(0.1\).
  </p>

  $$P(A \cup B) = 0.3 + 0.2 - 0.1 = 0.4 \le 0.3 + 0.2$$

  <!-- SUBSECTION: INCLUSION EXCLUSION -->
  <h4>4.2 Inclusion–Exclusion (Two and Three Events)</h4>

  <p>For two events:</p>

  $$
  P(A \cup B) = P(A) + P(B) - P(A \cap B)
  $$

  <p>For three events:</p>

  $$
  P(A \cup B \cup C) =
  P(A)+P(B)+P(C)
  -\big[P(A\cap B)+P(A\cap C)+P(B\cap C)\big]
  +P(A\cap B\cap C).
  $$

  <p><strong>Numerical example:</strong></p>

  Let:
  - \(P(A)=0.4\)  
  - \(P(B)=0.3\)  
  - \(P(C)=0.2\)  
  - pairwise intersections = \(0.1\)  
  - triple intersection = \(0.05\)

  Then:

  $$
  P(A \cup B \cup C)
  = 0.4 + 0.3 + 0.2
  - (0.1 + 0.1 + 0.1)
  + 0.05
  = 0.75
  $$

  <p>This illustrates how inclusion–exclusion systematically corrects for double-counting and triple-counting.</p>


  <!-- SUBSECTION: GENERAL FORM -->
  <h4>4.3 General Inclusion–Exclusion Formula</h4>

  <p>
    For \(n\) events, the union probability is:
  </p>

  $$
  P\!\left(\bigcup_{i=1}^n A_i\right)
  = \sum_{i=1}^n P(A_i)
  - \sum_{1 \le i < j \le n} P(A_i \cap A_j)
  + \sum_{1 \le i < j < k \le n} P(A_i \cap A_j \cap A_k)
  - \cdots
  + (-1)^{n+1} P(A_1 \cap \cdots \cap A_n).
  $$

  <p><strong>Intuition:</strong></p>
  <ul>
    <li>Add all individual probabilities</li>
    <li>Subtract all pair intersections (they were counted twice)</li>
    <li>Add triple intersections (they were subtracted too many times)</li>
    <li>Continue alternating until the highest-order intersection</li>
  </ul>

  <p>This principle is foundational in combinatorics, statistics, reliability engineering, and cybersecurity risk models.</p>

  <hr>
  <a href="index.html" class="back-button">← Back to Home</a>

</div>
</main>

<footer class="site-footer">
  © 2025 Alexandru Silivas — ID 2252622 — 
  <a href="mailto:silivas.2252622@studenti.uniroma1.it">
    silivas.2252622@studenti.uniroma1.it
  </a>
</footer>

</body>
</html>
